# 《Python数据分析与挖掘实战》学习笔记

[TOC]

## 写在前面

- 封面 | 摘要 | 关键词

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/3b6896c35a724a55b07d1a07b97f16d5.png)

  ```
  前言
  基础篇
  第1章　数据挖掘基础2
  1.1　某知名连锁餐饮企业的困惑2
  1.2　从餐饮服务到数据挖掘3
  1.3　数据挖掘的基本任务4
  1.4　数据挖掘建模过程4
  1.4.1　定义挖掘目标4
  1.4.2　数据取样5
  1.4.3　数据探索6
  1.4.4　数据预处理7
  1.4.5　挖掘建模7
  1.4.6　模型评价7
  1.5　常用的数据挖掘建模工具7
  1.6　小结9
  第2章　Python数据分析简介10
  2.1　搭建Python开发平台12
  2.1.1　所要考虑的问题12
  2.1.2　基础平台的搭建12
  2.2　Python使用入门13
  2.2.1　运行方式14
  2.2.2　基本命令15
  2.2.3　数据结构17
  2.2.4　库的导入与添加20
  2.3　Python数据分析工具22
  2.3.1　Numpy23
  2.3.2　Scipy24
  2.3.3　Matplotlib24
  2.3.4　Pandas26
  2.3.5　StatsModels27
  2.3.6　Scikit-Learn28
  2.3.7　Keras29
  2.3.8　Gensim30
  2.4　配套资源使用设置31
  2.5　小结32
  第3章　数据探索33
  3.1　数据质量分析33
  3.1.1　缺失值分析34
  3.1.2　异常值分析34
  3.1.3　一致性分析37
  3.2　数据特征分析37
  3.2.1　分布分析37
  3.2.2　对比分析40
  3.2.3　统计量分析41
  3.2.4　周期性分析44
  3.2.5　贡献度分析45
  3.2.6　相关性分析47
  3.3　Python主要数据探索函数50
  3.3.1　基本统计特征函数50
  3.3.2　拓展统计特征函数53
  3.3.3　统计作图函数54
  3.4　小结59
  第4章　数据预处理60
  4.1　数据清洗60
  4.1.1　缺失值处理60
  4.1.2　异常值处理64
  4.2　数据集成64
  4.2.1　实体识别64
  4.2.2　冗余属性识别65
  4.3　数据变换65
  4.3.1　简单函数变换65
  4.3.2　规范化66
  4.3.3　连续属性离散化68
  4.3.4　属性构造70
  4.3.5　小波变换71
  4.4　数据规约74
  4.4.1　属性规约74
  4.4.2　数值规约77
  4.5　Python主要数据预处理函数80
  4.6　小结81
  第5章　挖掘建模83
  5.1　分类与预测83
  5.1.1　实现过程83
  5.1.2　常用的分类与预测算法84
  5.1.3　回归分析85
  5.1.4　决策树89
  5.1.5　人工神经网络95
  5.1.6　分类与预测算法评价100
  5.1.7　Python分类预测模型特点103
  5.2　聚类分析104
  5.2.1　常用聚类分析算法104
  5.2.2　K-Means聚类算法105
  5.2.3　聚类分析算法评价111
  5.2.4　Python主要聚类分析算法111
  5.3　关联规则113
  5.3.1　常用关联规则算法114
  5.3.2　Apriori算法114
  5.4　时序模式119
  5.4.1　时间序列算法120
  5.4.2　时间序列的预处理120
  5.4.3　平稳时间序列分析122
  5.4.4　非平稳时间序列分析124
  5.4.5　Python主要时序模式算法132
  5.5　离群点检测134
  5.5.1　离群点检测方法135
  5.5.2　基于模型的离群点检测方法136
  5.5.3　基于聚类的离群点检测方法138
  5.6　小结141
  实战篇
  第6章　电力窃漏电用户自动识别144
  6.1　背景与挖掘目标144
  6.2　分析方法与过程147
  6.2.1　数据抽取148
  6.2.2　数据探索分析148
  6.2.3　数据预处理151
  6.2.4　构建专家样本156
  6.2.5　模型构建157
  6.3　上机实验161
  6.4　拓展思考162
  6.5　小结163
  第7章　航空公司客户价值分析164
  7.1　背景与挖掘目标164
  7.2　分析方法与过程166
  7.2.1　数据抽取168
  7.2.2　数据探索分析168
  7.2.3　数据预处理169
  7.2.4　模型构建173
  7.3　上机实验177
  7.4　拓展思考178
  7.5　小结179
  第8章　中医证型关联规则挖掘180
  8.1　背景与挖掘目标180
  8.2　分析方法与过程181
  8.2.1　数据获取183
  8.2.2　数据预处理186
  8.2.3　模型构建190
  8.3　上机实验193
  8.4　拓展思考194
  8.5　小结194
  第9章　基于水色图像的水质评价195
  9.1　背景与挖掘目标195
  9.2　分析方法与过程195
  9.2.1　数据预处理197
  9.2.2　模型构建199
  9.2.3　水质评价201
  9.3　上机实验202
  9.4　拓展思考202
  9.5　小结203
  第10章　家用电器用户行为分析与事件识别204
  10.1　背景与挖掘目标204
  10.2　分析方法与过程205
  10.2.1　数据抽取206
  10.2.2　数据探索分析207
  10.2.3　数据预处理207
  10.2.4　模型构建217
  10.2.5　模型检验219
  10.3　上机实验220
  10.4　拓展思考221
  10.5　小结222
  第11章　应用系统负载分析与磁盘容量预测223
  11.1　背景与挖掘目标223
  11.2　分析方法与过程225
  11.2.1　数据抽取226
  11.2.2　数据探索分析226
  11.2.3　数据预处理227
  11.2.4　模型构建229
  11.3　上机实验235
  11.4　拓展思考236
  11.5　小结237
  第12章　电子商务网站用户行为分析及服务推荐238
  12.1　背景与挖掘目标238
  12.2　分析方法与过程240
  12.2.1　数据抽取242
  12.2.2　数据探索分析244
  12.2.3　数据预处理251
  12.2.4　模型构建256
  12.3　上机实验266
  12.4　拓展思考267
  12.5　小结269
  第13章　财政收入影响因素分析及预测模型270
  13.1　背景与挖掘目标270
  13.2　分析方法与过程272
  13.2.1　灰色预测与神经网络的组合模型273
  13.2.2　数据探索分析274
  13.2.3　模型构建277
  13.3　上机实验294
  13.4　拓展思考295
  13.5　小结296
  第14章　基于基站定位数据的商圈分析297
  14.1　背景与挖掘目标297
  14.2　分析方法与过程299
  14.2.1　数据抽取299
  14.2.2　数据探索分析299
  14.2.3　数据预处理301
  14.2.4　模型构建304
  14.3　上机实验308
  14.4　拓展思考309
  14.5　小结309
  第15章　电商产品评论数据情感分析310
  15.1　背景与挖掘目标310
  15.2　分析方法与过程310
  15.2.1　评论数据采集311
  15.2.2　评论预处理314
  15.2.3　文本评论分词320
  15.2.4　模型构建320
  15.3　上机实验333
  15.4　拓展思考334
  15.5　小结335
  参考文献336
  ```

- 读后感

  1. 这？字典变成自编？是我有问题，还是你有问题？都出书了，为什么会有这种低级问题？

     ![在这里插入图片描述](https://img-blog.csdnimg.cn/e59bcf39871f43e2a7c2705fd0f67477.png)

- 摘抄

  1. matplotlib显示中文和负号

     ```python
     plt.rcParams['font.sans-serif'] = ['SimHei']
     plt.rcParams['axes.unicode_minus'] = False
     ```

     

- 传送门

## 1. 数据挖掘基础

1. 数据挖掘建模过程

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/ccd35e0b46ca4e108d390b2ba82c882d.png)

   - 定义挖掘目标
   - 数据采样
   - 数据探索
   - 数据预处理
   - 挖掘建模
   - 模型评价

2. 常用的数据挖掘建模工具

   1. SAS Enterprise Miner
   2. IBM SPSS Modeler
   3. SQL Server
   4. Python
   5. WEKA
   6. KNIME
   7. RapidMiner/YALE
   8. TipDM

## 2. Python数据分析简介

1. 列表list可以修改，元组tuple不可以

2. 其他创建字典dict的方法：
   - `dict([['A', 1], ['B', 2]])`
   - `dict.fromkeys(['A', 'B'], 0)`

3. 集合：set，{}
   - 元素不重复
   - 无序
   - 不支持索引

4. `map`：`map(lambda x, y: x*y, a: list, b: list)`
   - 逐一遍历
   - map效率更高，并且是懒加载

5. `reduce`：
   - 递归计算
   - `reduce(lambda x,y : x*y, range(1, n+1))`

6. `filter`：

   - `filter(lambda x: x > 5 and x < 8, range(10))`
   - 总结：操作上不如**列表表达式**，但是效率上快于列表表达式

7. Python数据挖掘相关扩展库

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/617a5b045820476bb673468e9389d332.png)
   
8. keras使用

   ```python
   from tensorflow.keras import Sequential
   from tensorflow.keras.layers import Dense, Dropout, Activation
   from tensorflow.keras.optimizers import SGD
   
   model = Sequential()
   model.add(Dense(64, input_shape=(20, )))
   model.add(Activation('tanh'))
   model.add(Dropout(0.5))
   model.add(Dense(64))
   model.add(Activation('tanh'))
   model.add(Dropout(0.5))
   model.add(Dense(1))
   model.add(Activation('sigmoid'))
   
   sgd = SGD(learning_rate=0.1, decay=1e-6, momentum=0.9, nesterov=True)
   model.compile(loss='mean_squared_error', optimizer=sgd)
   
   model.fit(X_train, y_train, nb_epoch-20, batch_size=16)
   score = model.evaluate(X_test, y_test, batch_size=16)
   ```


## 3. 数据探索

### 3.1 数据质量分析

脏数据

- 缺失值
- 异常值
- 不一致的值
- 重复数据
- 含有特殊符号的数据，如#、￥、*等

#### ① 缺失值分析

数据的缺失主要包括记录的缺失和记录中某个字段信息的缺失，两者都会造成统计结果不准确。

1. 缺失值产生的原因：
   1. 有些信息暂时无法获取，或者获取信息的代价太大。
   2. 有些信息是被遗漏的（人为因素和非人为原因）。
   3. 属性值不存在（例如未婚者的配偶姓名）。
2. 缺失值的影响：
   1. 数据挖掘建模将丢失大量的有用信息。
   2. 数据挖掘模型所表现出的不确定性更加显著，模型中蕴含的规律更难把握。
   3. 包含空值的数据会使建模过程陷入混乱，导致不可靠的输出。
3. 缺失值的分析：
   1. 使用简单的统计分析，可以得到含有缺失值的属性的个数，以及每个属性的未缺失数、缺失数与缺失率等。
   2. 从总体上来说，缺失值的处理分为
      1. 删除存在缺失值的记录
      2. 对可能值进行插补
      3. 不处理

#### ② 异常值分析

异常值分析是检验数据是否有录入错误以及含有不合常理的数据。异常值是指样本中的个别值，其数据明显偏离其余的观测值。异常值也称为离散点，异常值的分析也称为离群点分析。

1. 简单统计量分析

   对变量做一个描述性统计，进而查看不合理数据。最常用的统计量是最大值和最小值，用来判断这个变量的取值是否超出了合理的范围。

2. 3σ原则

   如果数据服从正态分布，在3σ原则下，异常值被定义为一组测定值中与平均值的偏差超过3倍标准差的值。这种值的出现属于小概率事件。如果数据不服从正态分布，也可以用远离平均值的多少倍标准差来描述。

3. 箱型图分析

   箱型图定义，异常值为小于QL - 1.5IQR 或大于QU + 1.5IQR 的值。

   其中，QL称为下四分位数，表示全部观察值中有四分之一的数据取值比它小；QU称为上四分位数，表示全部观察值中有四分之一的数据取值比它大；IQR称为四分位数间距，是QU与QL之差，其间包含了全部观察值的一半。

   ![在这里插入图片描述](https://img-blog.csdnimg.cn/6b5b9332a62a4826a1e7765792f2e821.png)

#### ③ 一致性分析

数据不一致性是指数据的矛盾性、不相容性。

不一致数据的产生主要发生在数据集成的过程中，可能由于被挖掘数据是来自于从不同的数据源、对于重复存放的数据未能进行一致性更新造成的。

### 3.2 数据特征分析

#### ① 分布分析

分布分析能揭示数据的分布特征和分布类型。

对于定量数据，欲了解其分布形式是对称的还是非对称的，发现某些特大或特小的可疑值，课通过绘制频率分布表、绘制频率分布直方图、绘制茎叶图进行值观地分析；对于定性分析数据，可用饼图和条形图直观地显示分布情况。

1. 定量数据的分布分析

   对定量变量而言，选择“组数”和“组宽”是做频率分布分析时最主要的问题，按以下步骤进行：

   1. 求极差
   2. 决定组距与组数
   3. 决定分点
   4. 列出频率分布表
   5. 绘制频率分布直方图

   遵循的主要原则：

   1. 各组直接必须是相互排斥的
   2. 各组必须将所有的数据包含在内
   3. 各组的组宽最好相等

2. 定性数据的分布分析

   - 对于定性变量，常常根据变量的分类类型来分组，可以采用饼图和条形图来描述定性变量的分布

#### ② 对比分析

1. 绝对数比较
2. 相对数比较
   1. 结构相对数
   2. 比例相对数
   3. 比较相对数
   4. 强度相对数
   5. 计划完成程度相对数
   6. 动态相对数

#### ③ 统计量分析

1. 集中趋势：均值、中位数、众数

2. 离中趋势：极差、标准差、方差、变异系数、四分位间距

   - 变异系数度量 **标准差** 相对于 **均值** 的离中趋势，计算公示为：
     $$
     CV=\frac{s}{\overline{x}}\times100\%
     $$
     变异系数主要用来比较两个或多个具有不同单位或不同波动幅度的数据集的离中趋势

   - 四分位数间距：上四分位数$Q_U$与下四分位数$Q_L$之差，其间包含了全部观察值的一半。其值越大，说明数据的 **变异程度** 越大，反之越小。

#### ④ 周期性分析

#### ⑤ 贡献度分析

- 又：帕累托分析
- 帕累托法则：又称20/80定律。同样的投入放在不同的地方会产生不同的效益。

#### ⑥ 相关性分析

1. 直接绘制散点图

2. 绘制散点图矩阵

3. 计算相关系数

   1. Pearson相关系数

      **是对定距变量的统计**

      - 连续变量

      - 假设条件：

        a) 两个变量分别服从正态分布，通常用t检验检查相关系数的显著性；

        b) 两个变量的标准差不为0。

      - pearson 描述的是线性相关关系，取值[-1, 1]。负数表示负相关，正数表示正相关。在显著性的前提下，绝对值越大，相关性越强。绝对值为0， 无线性关系；绝对值为1表示完全线性相关。

      - 公式：

        ![pearson](https://pic2.zhimg.com/80/v2-0c8e4244ca787cd806c85c2dfa1bdf59_1440w.webp)

   2. [Spearman秩相关系数](https://zhuanlan.zhihu.com/p/339077538)

      **是对定序变量的统计**

      - 连续变量

      - 无参数的等级相关系数，亦即其值与两个相关变量的具体值无关，而仅仅与其值之间的大小关系有关。$d_i$表示两个变量分别排序后成对的变量位置差，$N$表示$N$个样本，减少异常值的影响。

      - 公式：

        ![spearman](https://pic4.zhimg.com/80/v2-fdd4fdb80002ece8d070b828ce900123_1440w.webp)

      - 皮尔逊相关系数适用于线性关系，而斯皮尔曼相关系数适用于单调关系，线性与单调的一个区别是，线性关系的斜率是固定的。如果数据看上去，既有点像线性关系，又有点像单调关系，那么使用斯皮尔曼相关系数；皮尔逊相关系数使用元数据进行计算的，而斯皮尔曼相关系数是基于秩计算的。

   3. *[Kendall相关系数](https://zhuanlan.zhihu.com/p/60059869)*

      - 有序分类变量

      - 属于等级相关系数。排序一致，则为1， 排序完全相反则为-1。

      - [公式：](https://www.jianshu.com/p/9dec47bac5b9)

        ![Tau-a](https://math.jianshu.com/math?formula=T%20a%20u-a%3D%5Cfrac%7BC-D%7D%7B%5Cfrac%7B1%7D%7B2%7D%20N(N-1)%7D)

        ![Tau-b](https://math.jianshu.com/math?formula=T%20a%20u-b%3D%5Cfrac%7BC-D%7D%7B%5Csqrt%7B(N%203-N%201)(N%203-N%202)%7D%7D)

        ![Tau-c](https://math.jianshu.com/math?formula=T%20a%20u-c%3D%5Cfrac%7BC-D%7D%7B%5Cfrac%7B1%7D%7B2%7D%20N%5E%7B2%7D%20%5Cfrac%7BM-1%7D%7BM%7D%7D)

      [小结：](https://guyuecanhui.github.io/2019/08/10/feature-selection-kendall/)

      1. **Kendall** 秩相关系数可以用于度量有序变量间相关性，只要求变量取值之间可比，对变量的分布和数据的距离不作假设；

      2. 能用 **Pearson** 相关系数和 **Spearman** 秩相关系数的地方都能用 **Kendall** 秩相关系数，但是 **Spearman** 和 **Kendall** 秩相关系数要对数据排序，复杂度远高于 **Pearson** 相关系数，因此能用 **Pearson** 相关系数的时候优先考虑 **Pearson** 相关系数；

      3. **Kendall** 秩相关系数依赖一致对和分歧对的计数，这里需要注意数据中是否有重复取值的情况，来选择使用 **Tau-a** 还是 **Tau-b** 进行计算。

      4. [Pearson相关与Spearman和Kendall相关](https://www.jianshu.com/p/9dec47bac5b9)

         非参数相关（指 spearman和kendall）的表达能力相对较弱，因为它们在计算中使用的信息较少。在Pearson的情况下，相关性使用有关均值和均值偏差的信息，而非参数相关性仅使用序数信息和成对分数。

         在非参数相关的情况下，X和Y值可能是连续的或有序的，并且不需要X和Y的近似正态分布。但在皮尔逊相关的情况下，它假定X和Y的分布应该是正态分布，并且也应该是连续的（**因此做pearson之前要做一些对数变换之类的尽量接近正态分布**）。

      5. Spearman相关与Kendall相关

         在正常情况下，Kendall相关性比Spearman相关性更强健和有效。这意味着当样本量较小或存在一些异常值时，首选Kendall相关。

         相关系数是测量**线性**（皮尔逊）或 **单调**（Spearman和Kendall）关系。

   4. 判定系数：pearson相关系数的平方：$r^2$

### 3.3 Python主要数据探索函数

#### ① 基本统计特征函数

![在这里插入图片描述](https://img-blog.csdnimg.cn/2f8f9d2cf8564cdc979d4a774aea7cd1.png)

- `corr(method='pearson')`：计算数据样本的相关系数矩阵，支持pearson(default)、spearman、kendall

#### ② 拓展统计特征函数

![在这里插入图片描述](https://img-blog.csdnimg.cn/5ee205f9840f47aab47b07654babfb2f.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/7c80ff6e2e94465b9da3c249ca1a9d55.png)

- cum系列函数是作为DataFrame或Series对象的方法而出现的，`D.cumsum()`
- rolling系列是pandas的函数，不是DataFrame或Series对象的方法，`pd.rolling_mean(D, k)`，意思是每k列计算一次均值，滚动计算

#### ③ 统计作图函数

![在这里插入图片描述](https://img-blog.csdnimg.cn/55c16974ef014e779e38f77cc6044a57.png)

- 盒图：表示多个样本的均值

- 误差条形图：同时显示下限误差和上限误差

- 最小二乘拟合曲线图：分析两两变量间的关系

- `plt.plot(x, y, S)`：S指定绘制时图形的类型、样式和颜色

  - `r`、`g`、`b`
  - `o`、`+`、`p`
  - `-`、`--`、`=`

- `D.plot(kind='box')`：kind参数用来指定作图的类型

  - `line`、`bar`、`barh`、`hist`、`box`、`kde`、`area`、`pie`

- 饼状图绘制示例

  ```python
  labels = ['Frogs', 'Hogs', 'Dogs', 'Logs']
  sizes = [15, 30, 45, 10]
  colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']
  explode = (0, 0.1, 0, 0)
  
  plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)
  # 显示为圆，避免比例压缩为椭圆
  plt.axis('equal')
  plt.show()
  ```

  ![请添加图片描述](https://img-blog.csdnimg.cn/4032ce8a66784e6a908d88c6d1d9e92c.png)


## 4. 数据预处理

数据预处理的主要内容包括：数据清洗、数据集成、数据变换和数据规约。

![在这里插入图片描述](https://img-blog.csdnimg.cn/ae85c1f29c354d0fa92178e63603559e.png)

### 4.1 数据清洗

数据清洗主要是删除原始数据集中的无关数据、重复数据，平滑噪声数据，筛选掉与挖掘主题无关的数据、处理缺失值、异常值等。

#### ① 缺失值处理

处理缺失值的方法可分为3类：删除记录、数据插补和不处理。

- 常用的插补方法：

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/df15d6180d3942ac8ce61de2880e91a2.png)

- 常用的插值方法：拉格朗日插值法、牛顿插值法、Hermite插值、分段插值、样条插值法等。

  - 拉格朗日插值公式结构紧凑，在理论分析中很方便，但是当插值节点增减时，插值多项式就会随之变化，这在实际计算中是很不方便的，为了克服这一缺点，提出了牛顿插值法。
  - 牛顿插值法也是多项式插值，但采用了另一种构造插值多项式的方法，与拉格朗日插值相比，具有承袭性和易于变动节点的特点。从本质上来说，两者给出的结果是一样的(相同次数、相同系数的多项式)，只不过表示的形式不同。因此，在 Python 的 Scipy 库中，只提供了拉格朗日插值法的函数(因为实现上比较容易)。

#### ② 异常值处理

- 常用的异常值处理方法：

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/26cf639dfb2643888f64e5f6fc8a7ed6.png)

- 在很多情况下，要先分析异常值出现的可能原因，再判断异常值是否应该舍弃，如果是正确的数据，可以直接在具有异常值的数据集上进行挖掘建模。

### 4.2 数据集成

在数据集成时，来自多个数据源的现实世界实体的表达形式是不一样的，有可能不匹配，要考虑实体识别问题和属性冗余问题，从而将源数据在最低层上加以转换、提炼和集成。

#### ① 实体识别	

- 实体识别：从不同数据源识别处现实世界的实体，它的任务是统一不同源数据的矛盾之处。
- 常见形式：
  - 同名异义
  - 异名同义
  - 单位不统一

#### ② 冗余属性识别

- 常见形式：
  - 同一属性出现多次
  - 同一属性命名不一致导致重复
- 有些冗余属性可以用相关分析检测。给定两个数值型的属性 A 和 B，根据其属性值，用相关系数度量一个属性在多大程度上蕴含另一个属性。

### 4.3 数据变换

数据变换主要是对数据进行规范化处理，将数据转换成“适当的”形式，以适用于挖掘任务及算法的需要。

#### ① 简单函数变换

- 简单函数变换是对原始数据进行某些数学函数变换，常用的变换包括平方、开方、取对数、差分运算等。
- 简单的函数变换常用来将不具有正态分布的数据变换成具有正态分布的数据。在时间序列分析中，有时简单的对数变换或者差分运算就可以将非平稳序列转换成平稳序列。

#### ② 规范化

数据规范化(归一化)处理是数据挖掘的一项基础工作。不同评价指标往往具有不同的量纲，数值间的差别可能很大，不进行处理可能会影响到数据分析的结果。为了消除指标之间的量纲和取值范围差异的影响，需要进行标准化处理，将数据按照比例进行缩放，使之落入一个特定的区域，便于进行综合分析。数据规范化对于基于距离的挖掘算法尤为重要。

- 最小-最大规范化：离差标准化 $x^* = \frac{x-min}{max-min}$
- 零-均值规范化：标准差标准化 $x^*=\frac{x-\overline{x}}{\sigma}$
- 小数定标规范化：讲属性映射到`[-1, 1]`之间 $x^*=\frac{x}{10^k}$

#### ③ 连续属性离散化

一些数据挖掘算法，特别是某些分类算法(如ID3 算法、Apriori 算法等)，要求数据是分类属性形式。这样，常常需要将连续属性变换成分类属性，即连续属性离散化。

- 离散化的过程：连续属性的离散化就是在数据的取值范围内设定若干个离散的划分点，将取值范围划分为一些离散化的区间，最后用不同的符号或整数值代表落在每个子区间中的数据值。
- 常用的离散化方法：
  - 等宽法
  - 等频法
  - 基于聚类分析的方法

#### ④ 属性构造

在数据挖掘的过程中，为了提取更有用的信息，挖掘更深层次的模式，提高挖掘结果的精度，我们需要利用已有的属性集构造出新的属性，并加入到现有的属性集合中。

#### ⑤ 小波变换

- 小波变换是一种新型的数据分析工具，是近年来兴起的信号分析手段。

- 小波分析的理论和方法在信号处理、图像处理、语音处理、模式识别、量子物理等领域得到越来越广泛的应用，它被认为是近年来在工具及方法上的重大突破。小波变换具有多分辨率的特点，在时域和频域都具有表征信号局部特征的能力，通过伸缩和平移等运算过程对信号进行多尺度聚焦分析，提供了一种非平稳信号的时频分析手段，可以由粗及细地逐步观察信号，从中提取有用信息。

- 能够刻画某个问题的特征量往往是隐含在一个信号中的某个或者某些分量中，小波变换可以把非平稳信号分解为表达不同层次、不同频带信息的数据序列，即小波系数。选取适当的小波系数，即完成了信号的特征提取。

- 基于小波变换的信号特征提取方法：

  - 基于小波变换的 **多尺度空间能量分布** 特征提取方法：各尺度空间内的平滑信号和细节信号能提供原始信号的时频局域信息，特别是能提供不同频段上信号的构成信息。把不同分解尺度上信号的能量求解出来，就可以将这些能量尺度顺序排列，形成特征向量供识别用。
  - 基于小波变换的 **多尺度空间的模极大值** 特征提取方法：利用小波变换的信号局域化分析能力，求解小波变换的模极大值特性来检测信号的局部奇异性，将小波变换模极大值的尺度参数 s、平移参数及其幅值作为目标的特征量
  - 基于小波 **包变换** 的特征提取方法：利用小波分解，可将时域随机信号序列映射为尺度域各子空间内的随机系数序列，按小波包分解得到的最佳子空间内随机系数序列的不确定性程度最低将最佳子空间的熵值及最佳子空间在完整二叉树中的位置参数作为特征量，可以用于目标识别
  - 基于 **适应性小波神经网络** 的特征提取方法：基于适应性小波神经网络的特征提取方法可以把信号通过分析小波拟合表示，进行特征提取

- 小波基函数：

  - 小波基函数是一种具有局部支集的函数，并且平均值为 0，小波基函数满足 $\psi(0)=\int{\psi(t)dt}=0$。常用的小波基有 Haar 小波基、db 系列小波基等。

- 小波变换

  - 对小波基函数进行伸缩和平移变换：
    $$
    \psi_{a,b}(t)=\frac{1}{\sqrt{\abs{a}}}\psi(\frac{t-b}{a})
    $$
    其中，a为伸缩因子，b为平移因子

  - 任意函数 $f(t)$ 的连续小波变换（CWT）为：
    $$
    W_f(a,b)=\abs{a}^{-1/2}\int{f(t)\psi(\frac{t-b}{a})dt}
    $$

  - 可知，连续小波变换为 $f(t) \rightarrow W_f(a,b)$ 的映射，对小波基函数 $\psi(t)$ 增加约束条件 $C_\psi=\int{\frac{\abs{\widehat{\psi}(t)}^2}{t}dt}<\infty$，就可以由 $W_f(a,b)$ 逆变换得到 $f(t)$ ，其中 $\widehat{\psi}(t)$ 为 $\psi(t)$ 的傅里叶变换。

  - 其逆变换为：
    $$
    f(t)=\frac{1}{C_\psi}\int\int{\frac{1}{a^2}W_f(a,b)\psi(\frac{t-b}{a})da \cdot db}
    $$

- 基于小波变换的多尺度空间能量分布特征提取方法

  - 应用小波分析技术可以把信号在各频率波段中的特征提取出来，基于小波变换的多尺度空间能量分布特征提取方法是对信号进行频带分析，再分别以计算所得的各个频带的能量作为特征向量。


### 4.4 数据规约

- 在大数据集上进行复杂的数据分析和挖掘需要很长的时间，数据规约产生更小但保持原数据完整性的新数据集。在规约后的数据集上进行分析和挖掘将更有效率。
- 数据规约的意义在于:
  - 降低无效、错误数据对建模的影响，提高建模的准确性
  - 少量且具代表性的数据将大幅缩减数据挖掘所需的时间
  - 降低储存数据的成本

#### ① 属性规约

- 属性规约通过属性合并来创建新属性维数，或者直接通过删除不相关的属性(维)来减少数据维数，从而提高数据挖掘的效率、降低计算成本。属性规约的目标是 **寻找出最小的属性子集并确保新数据子集的概率分布尽可能地接近原来数据集的概率分布。**

- 属性规约常用方法

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/f6a41bcac9934a0cbcdee2f76b61c494.png)

- 






























------


- :cloud: 我的CSDN：`https://blog.csdn.net/qq_21579045`
- :snowflake: 我的博客园：`https://www.cnblogs.com/lyjun/`
- :sunny: 我的Github：`https://github.com/TinyHandsome`
- :rainbow: 我的bilibili：`https://space.bilibili.com/8182822`
- :avocado: 我的思否：`https://segmentfault.com/u/liyj`
- :tomato: 我的知乎：`https://www.zhihu.com/people/lyjun_`
- :penguin: 粉丝交流群：1060163543，神秘暗号：为干饭而来

碌碌谋生，谋其所爱。:ocean:              @李英俊小朋友
