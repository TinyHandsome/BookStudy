---
annotation-target: AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf
---




>%%
>```annotation-json
>{"created":"2025-01-21T07:08:12.944Z","text":"能够在不同领域和应用程序中感知和行动的智能体系统的概述。\n- perceive：感知","updated":"2025-01-21T07:08:12.944Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":414,"end":509},{"type":"TextQuoteSelector","exact":"Overview of an Agent AI system that can perceive and act in different domains and applications.","prefix":"ton; 5Microsoft GamingFigure 1: ","suffix":" Agent AI isemerging as a promis"}]}]}
>```
>%%
>*%%PREFIX%%ton; 5Microsoft GamingFigure 1:%%HIGHLIGHT%% ==Overview of an Agent AI system that can perceive and act in different domains and applications.== %%POSTFIX%%Agent AI isemerging as a promis*
>%%LINK%%[[#^n8n1jqxyfrp|show annotation]]
>%%COMMENT%%
>能够在不同领域和应用程序中感知和行动的智能体系统的概述。
>- perceive：感知
>%%TAGS%%
>
^n8n1jqxyfrp


>%%
>```annotation-json
>{"created":"2025-01-21T07:10:32.954Z","text":"AI智能体正在成为通往通用人工智能(AGI)的有前途的途径。\n- emerge as：成为\n- promising avenue：有前途的途径","updated":"2025-01-21T07:10:32.954Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":510,"end":598},{"type":"TextQuoteSelector","exact":"Agent AI isemerging as a promising avenue toward Artificial General Intelligence (AGI). ","prefix":"erent domains and applications. ","suffix":"Agent AI training has demonstrat"}]}]}
>```
>%%
>*%%PREFIX%%erent domains and applications.%%HIGHLIGHT%% ==Agent AI isemerging as a promising avenue toward Artificial General Intelligence (AGI).== %%POSTFIX%%Agent AI training has demonstrat*
>%%LINK%%[[#^rc64d3s38ca|show annotation]]
>%%COMMENT%%
>AI智能体正在成为通往通用人工智能(AGI)的有前途的途径。
>- emerge as：成为
>- promising avenue：有前途的途径
>%%TAGS%%
>
^rc64d3s38ca


>%%
>```annotation-json
>{"created":"2025-01-21T07:13:59.577Z","text":"它提供了一个不依赖于现实的训练框架，通过利用生成式AI和多个独立的数据源来实现。\n- reality-agnostic：不依赖于现实\n- agnostic：不可知论\n- leverage：杠杆，利用，影响力\n- alongside：沿着","updated":"2025-01-21T07:13:59.577Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":698,"end":824},{"type":"TextQuoteSelector","exact":"It provides a framework for reality-agnostic training byleveraging generative AI alongside multiple independent data sources. ","prefix":"standing in the physical world. ","suffix":"Large foundation models trained "}]}]}
>```
>%%
>*%%PREFIX%%standing in the physical world.%%HIGHLIGHT%% ==It provides a framework for reality-agnostic training byleveraging generative AI alongside multiple independent data sources.== %%POSTFIX%%Large foundation models trained*
>%%LINK%%[[#^bzx7j2les6c|show annotation]]
>%%COMMENT%%
>它提供了一个不依赖于现实的训练框架，通过利用生成式AI和多个独立的数据源来实现。
>- reality-agnostic：不依赖于现实
>- agnostic：不可知论
>- leverage：杠杆，利用，影响力
>- alongside：沿着
>%%TAGS%%
>
^bzx7j2les6c


>%%
>```annotation-json
>{"created":"2025-01-21T07:29:30.537Z","text":"跨现实数据","updated":"2025-01-21T07:29:30.537Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":952,"end":970},{"type":"TextQuoteSelector","exact":"cross-reality data","prefix":" virtual worlds when trained on ","suffix":". We present thegeneral overview"}]}]}
>```
>%%
>*%%PREFIX%%virtual worlds when trained on%%HIGHLIGHT%% ==cross-reality data== %%POSTFIX%%. We present thegeneral overview*
>%%LINK%%[[#^ec0kqhdazq8|show annotation]]
>%%COMMENT%%
>跨现实数据
>%%TAGS%%
>
^ec0kqhdazq8


>%%
>```annotation-json
>{"created":"2025-01-21T07:31:35.737Z","text":"作为智能体范式实现AGI的途径","updated":"2025-01-21T07:31:35.737Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1103,"end":1157},{"type":"TextQuoteSelector","exact":"serving as a route towards AGI using an agent paradigm","prefix":"mains and applications, possibly","suffix":".∗Equal Contribution. ‡ Project "}]}]}
>```
>%%
>*%%PREFIX%%mains and applications, possibly%%HIGHLIGHT%% ==serving as a route towards AGI using an agent paradigm== %%POSTFIX%%.∗Equal Contribution. ‡ Project*
>%%LINK%%[[#^s1e2z1x0dns|show annotation]]
>%%COMMENT%%
>作为智能体范式实现AGI的途径
>%%TAGS%%
>
^s1e2z1x0dns


>%%
>```annotation-json
>{"created":"2025-01-21T08:11:45.527Z","text":"在日常生活中无处不在","updated":"2025-01-21T08:11:45.527Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1406,"end":1455},{"type":"TextQuoteSelector","exact":"ecome a ubiquitous presence in our everyday lives","prefix":"i-modal AI systems will likely b","suffix":". A promisingapproach to making "}]}]}
>```
>%%
>*%%PREFIX%%i-modal AI systems will likely b%%HIGHLIGHT%% ==ecome a ubiquitous presence in our everyday lives== %%POSTFIX%%. A promisingapproach to making*
>%%LINK%%[[#^qq2na4umu3h|show annotation]]
>%%COMMENT%%
>在日常生活中无处不在
>%%TAGS%%
>
^qq2na4umu3h


>%%
>```annotation-json
>{"created":"2025-01-21T08:13:07.094Z","text":"作为智能体嵌入\n- embody：嵌入","updated":"2025-01-21T08:13:07.094Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1524,"end":1544},{"type":"TextQuoteSelector","exact":"embody them as agent","prefix":" systems more interactive is to ","suffix":"s within physicaland virtual env"}]}]}
>```
>%%
>*%%PREFIX%%systems more interactive is to%%HIGHLIGHT%% ==embody them as agent== %%POSTFIX%%s within physicaland virtual env*
>%%LINK%%[[#^ii6kql95c07|show annotation]]
>%%COMMENT%%
>作为智能体嵌入
>- embody：嵌入
>%%TAGS%%
>
^ii6kql95c07


>%%
>```annotation-json
>{"created":"2025-01-21T08:14:34.793Z","text":"目前，系统利用现有的基础模型作为创建具身智能体的基本构建块。","updated":"2025-01-21T08:14:34.793Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1587,"end":1708},{"type":"TextQuoteSelector","exact":"At present, systems leverage existing foundation models as the basicbuilding blocks for the creation of embodied agents. ","prefix":"ysicaland virtual environments. ","suffix":"Embedding agents within such env"}]}]}
>```
>%%
>*%%PREFIX%%ysicaland virtual environments.%%HIGHLIGHT%% ==At present, systems leverage existing foundation models as the basicbuilding blocks for the creation of embodied agents.== %%POSTFIX%%Embedding agents within such env*
>%%LINK%%[[#^1rih37wcinj|show annotation]]
>%%COMMENT%%
>目前，系统利用现有的基础模型作为创建具身智能体的基本构建块。
>%%TAGS%%
>
^1rih37wcinj


>%%
>```annotation-json
>{"created":"2025-01-21T08:38:12.176Z","text":"促进","updated":"2025-01-21T08:38:12.176Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1749,"end":1761},{"type":"TextQuoteSelector","exact":"facilitates ","prefix":" agents within such environments","suffix":"the ability of models to process"}]}]}
>```
>%%
>*%%PREFIX%%agents within such environments%%HIGHLIGHT%% ==facilitates== %%POSTFIX%%the ability of models to process*
>%%LINK%%[[#^j34bqs57of|show annotation]]
>%%COMMENT%%
>促进
>%%TAGS%%
>
^j34bqs57of


>%%
>```annotation-json
>{"created":"2025-01-21T08:38:36.431Z","text":"处理和解释","updated":"2025-01-21T08:38:36.431Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1786,"end":1806},{"type":"TextQuoteSelector","exact":"process and interpre","prefix":"itates the ability of models to ","suffix":"t visual and contextual data, wh"}]}]}
>```
>%%
>*%%PREFIX%%itates the ability of models to%%HIGHLIGHT%% ==process and interpre== %%POSTFIX%%t visual and contextual data, wh*
>%%LINK%%[[#^nghsvy7fzp|show annotation]]
>%%COMMENT%%
>处理和解释
>%%TAGS%%
>
^nghsvy7fzp


>%%
>```annotation-json
>{"created":"2025-01-21T08:39:25.863Z","text":"这对于创建更复杂和具有上下文感知的AI系统至关重要。","updated":"2025-01-21T08:39:25.863Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":1835,"end":1920},{"type":"TextQuoteSelector","exact":" which is criticalfor the creation of more sophisticated and context-aware AI systems","prefix":"pret visual and contextual data,","suffix":". For example, a system that can"}]}]}
>```
>%%
>*%%PREFIX%%pret visual and contextual data,%%HIGHLIGHT%% ==which is criticalfor the creation of more sophisticated and context-aware AI systems== %%POSTFIX%%. For example, a system that can*
>%%LINK%%[[#^xwtttllkgmd|show annotation]]
>%%COMMENT%%
>这对于创建更复杂和具有上下文感知的AI系统至关重要。
>%%TAGS%%
>
^xwtttllkgmd


>%%
>```annotation-json
>{"created":"2025-01-21T08:40:35.197Z","text":"一个场景的集体情感。就是说一个场景的整体上要表的情绪。","updated":"2025-01-21T08:40:35.197Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2037,"end":2071},{"type":"TextQuoteSelector","exact":"the collectivesentiment of a scene","prefix":"objects, audio expressions, and ","suffix":" can be used to inform and direc"}]}]}
>```
>%%
>*%%PREFIX%%objects, audio expressions, and%%HIGHLIGHT%% ==the collectivesentiment of a scene== %%POSTFIX%%can be used to inform and direc*
>%%LINK%%[[#^nq9x9m72cw|show annotation]]
>%%COMMENT%%
>一个场景的集体情感。就是说一个场景的整体上要表的情绪。
>%%TAGS%%
>
^nq9x9m72cw


>%%
>```annotation-json
>{"created":"2025-01-21T08:43:19.485Z","text":"能够感知视觉刺激、语言输入和其他基于环境的数据，并能够产生有意义的具身化行为。","updated":"2025-01-21T08:43:19.485Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2271,"end":2403},{"type":"TextQuoteSelector","exact":" can perceive visual stimuli, language inputs, and other environmentally-grounded data, and can produce meaningful embodied actions.","prefix":"class ofinteractive systems that","suffix":" In particular, we explore syste"}]}]}
>```
>%%
>*%%PREFIX%%class ofinteractive systems that%%HIGHLIGHT%% ==can perceive visual stimuli, language inputs, and other environmentally-grounded data, and can produce meaningful embodied actions.== %%POSTFIX%%In particular, we explore syste*
>%%LINK%%[[#^vwydloo0va8|show annotation]]
>%%COMMENT%%
>能够感知视觉刺激、语言输入和其他基于环境的数据，并能够产生有意义的具身化行为。
>%%TAGS%%
>
^vwydloo0va8


>%%
>```annotation-json
>{"created":"2025-01-21T08:44:46.278Z","text":"整合外部知识","updated":"2025-01-21T08:44:46.278Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2508,"end":2539},{"type":"TextQuoteSelector","exact":"incorporating externalknowledge","prefix":"t-embodied action prediction by ","suffix":", multi-sensory inputs, and huma"}]}]}
>```
>%%
>*%%PREFIX%%t-embodied action prediction by%%HIGHLIGHT%% ==incorporating externalknowledge== %%POSTFIX%%, multi-sensory inputs, and huma*
>%%LINK%%[[#^2ror91k3se|show annotation]]
>%%COMMENT%%
>整合外部知识
>%%TAGS%%
>
^2ror91k3se


>%%
>```annotation-json
>{"created":"2025-01-21T08:44:59.170Z","text":"多感官输入","updated":"2025-01-21T08:44:59.170Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2541,"end":2561},{"type":"TextQuoteSelector","exact":"multi-sensory inputs","prefix":"ncorporating externalknowledge, ","suffix":", and human feedback. We argue t"}]}]}
>```
>%%
>*%%PREFIX%%ncorporating externalknowledge,%%HIGHLIGHT%% ==multi-sensory inputs== %%POSTFIX%%, and human feedback. We argue t*
>%%LINK%%[[#^qtrrz89x0hb|show annotation]]
>%%COMMENT%%
>多感官输入
>%%TAGS%%
>
^qtrrz89x0hb


>%%
>```annotation-json
>{"created":"2025-01-21T08:46:17.136Z","text":"现实环境中","updated":"2025-01-21T08:46:17.136Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2632,"end":2653},{"type":"TextQuoteSelector","exact":"grounded environments","prefix":"developing agentic AIsystems in ","suffix":", one can also mitigate the hall"}]}]}
>```
>%%
>*%%PREFIX%%developing agentic AIsystems in%%HIGHLIGHT%% ==grounded environments== %%POSTFIX%%, one can also mitigate the hall*
>%%LINK%%[[#^w31u0o60uw|show annotation]]
>%%COMMENT%%
>现实环境中
>%%TAGS%%
>
^w31u0o60uw


>%%
>```annotation-json
>{"created":"2025-01-21T08:47:00.404Z","text":"减轻幻觉","updated":"2025-01-21T08:47:00.404Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2668,"end":2695},{"type":"TextQuoteSelector","exact":"mitigate the hallucinations","prefix":"nded environments, one can also ","suffix":" of large foundationmodels and t"}]}]}
>```
>%%
>*%%PREFIX%%nded environments, one can also%%HIGHLIGHT%% ==mitigate the hallucinations== %%POSTFIX%%of large foundationmodels and t*
>%%LINK%%[[#^q1r4up12i3r|show annotation]]
>%%COMMENT%%
>减轻幻觉
>%%TAGS%%
>
^q1r4up12i3r


>%%
>```annotation-json
>{"created":"2025-01-21T08:48:42.731Z","text":"涵盖了更广泛的具身性和代理性","updated":"2025-01-21T08:48:42.731Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2819,"end":2867},{"type":"TextQuoteSelector","exact":"ubsumes the broader embodied and agentic aspects","prefix":" The emerging field of AgentAI s","suffix":" of multimodal interactions. Bey"}]}]}
>```
>%%
>*%%PREFIX%%The emerging field of AgentAI s%%HIGHLIGHT%% ==ubsumes the broader embodied and agentic aspects== %%POSTFIX%%of multimodal interactions. Bey*
>%%LINK%%[[#^o4uhm544njm|show annotation]]
>%%COMMENT%%
>涵盖了更广泛的具身性和代理性
>%%TAGS%%
>
^o4uhm544njm


>%%
>```annotation-json
>{"created":"2025-01-21T08:49:57.173Z","text":"设想了","updated":"2025-01-21T08:49:57.173Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":2958,"end":2967},{"type":"TextQuoteSelector","exact":"envision ","prefix":"cting in the physical world, we ","suffix":"a future where people can easily"}]}]}
>```
>%%
>*%%PREFIX%%cting in the physical world, we%%HIGHLIGHT%% ==envision== %%POSTFIX%%a future where people can easily*
>%%LINK%%[[#^4gvc319pxpo|show annotation]]
>%%COMMENT%%
>设想了
>%%TAGS%%
>
^4gvc319pxpo


>%%
>```annotation-json
>{"created":"2025-01-21T08:50:13.318Z","text":"模拟场景","updated":"2025-01-21T08:50:13.318Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":3030,"end":3045},{"type":"TextQuoteSelector","exact":"imulated scene ","prefix":"y create anyvirtual reality or s","suffix":"and interact with agents embodie"}]}]}
>```
>%%
>*%%PREFIX%%y create anyvirtual reality or s%%HIGHLIGHT%% ==imulated scene== %%POSTFIX%%and interact with agents embodie*
>%%LINK%%[[#^g7x8smkw6au|show annotation]]
>%%COMMENT%%
>模拟场景
>%%TAGS%%
>
^g7x8smkw6au


>%%
>```annotation-json
>{"created":"2025-01-21T08:51:20.711Z","text":"在虚拟环境中与具身智能交互","updated":"2025-01-21T08:51:20.711Z","document":{"title":"AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","link":[{"href":"urn:x-pdf:e41684937cf8542c02f4bf697c13228c"},{"href":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf"}],"documentFingerprint":"e41684937cf8542c02f4bf697c13228c"},"uri":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","target":[{"source":"vault:/Papers_/AGENT AI SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION.pdf","selector":[{"type":"TextPositionSelector","start":3049,"end":3109},{"type":"TextQuoteSelector","exact":"interact with agents embodied within the virtual environment","prefix":" reality or simulated scene and ","suffix":".Contents1 Introduction 51.1 Mot"}]}]}
>```
>%%
>*%%PREFIX%%reality or simulated scene and%%HIGHLIGHT%% ==interact with agents embodied within the virtual environment== %%POSTFIX%%.Contents1 Introduction 51.1 Mot*
>%%LINK%%[[#^yztgjqhq2l|show annotation]]
>%%COMMENT%%
>在虚拟环境中与具身智能交互
>%%TAGS%%
>
^yztgjqhq2l
